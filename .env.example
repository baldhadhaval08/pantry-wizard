# PantryWizard+ Environment Variables
# Copy this file to backend/.env and configure as needed

# Database Configuration
# SQLite (default) - no setup required
DATABASE_URL=sqlite:///./pantry.db

# PostgreSQL (optional) - uncomment and configure
# DATABASE_URL=postgresql://user:password@localhost:5432/pantrywizard

# JWT Authentication
JWT_SECRET=your-secret-key-change-in-production-use-random-string
JWT_ALGORITHM=HS256
JWT_EXPIRATION_HOURS=24

# LLM Configuration
# Mode: "local" for local models, "api" for external API
LLM_MODE=ollama

# API Mode Configuration (when LLM_MODE=api)
# OpenAI-compatible API endpoint
LLM_API_URL=https://api.openai.com/v1/chat/completions
# Your API key
LLM_API_KEY=your-api-key-here

# Local Mode Configuration (when LLM_MODE=local)
# Path to local model directory (optional, will download if not set)
LLM_MODEL_PATH=
# Model name from Hugging Face (used if LLM_MODEL_PATH not set)
LLM_MODEL_NAME=mistralai/Mistral-7B-Instruct-v0.2

# LLM Configuration - Using Ollama for local AI (when LLM_MODE=ollama)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral

# Image Generation
# Mode: "placeholder" (default), "local_sd" (Stable Diffusion), "api"
IMAGE_MODE=placeholder

# Stable Diffusion Configuration (when IMAGE_MODE=local_sd)
# Path to local SD model (optional)
SD_MODEL_PATH=
# SD model name from Hugging Face
SD_MODEL_NAME=runwayml/stable-diffusion-v1-5

# Hardware Configuration
# Enable CUDA for GPU acceleration (requires CUDA-capable GPU)
USE_CUDA=false
# Device: "cpu" or "cuda"
DEVICE=cpu

# CORS Origins (frontend URLs allowed to access API)
CORS_ORIGINS=["http://localhost:3000","http://localhost:3001"]

# API Configuration
API_V1_PREFIX=/api
